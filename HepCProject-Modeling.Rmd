---
title: "capstone_variablecreation"
author: "Laura Olson"
date: "May 20, 2017"
output: html_document
---

```{r}
#libraries being used in this file
library(dplyr)
library(ROSE)
library(rpart)


```


```{r}
#IMPORT DATA FROM PATIENTS FILES

##patients table only
#patients <- read.csv("Z:/Flat File/patients.csv", ",", header = TRUE)

## patients table with HEDIS only
#patients <- read.csv("Z:/Flat File/patients_HEDIS_20170816file.csv", ",", header = TRUE)

#patients table with HEDIS and CCS
patients <- read.csv("Z:/Flat File/patients_HEDIS_and_CCS_20170816file.csv", ",", header = TRUE)

dim(patients)

#remove the index column
patients <- patients[,-1]
dim(patients)


## bin patients by generation - add this to the variable creation file
#patients[,461]<-ifelse(patients$DOB_DS < 1945/01/01, "Silent", ifelse(patients$DOB_DS >= 1945/01/01 & patients$DOB_DS < 1964/01/01,"Baby Boomer", ifelse(patients$DOB_DS >= 1964/01/01 & patients$DOB_DS <1980/01/01, "Gen X",ifelse(patients$DOB_DS >= 1980/01/01, "Millennial", "Unknown"))))
#names(patients)[461]<-paste("GENERATION_CATEGORY")
#patients$GENERATION_CATEGORY <- as.factor(patients$GENERATION_CATEGORY)

#str(patients[,1:75])
#str(patients[,76:129])
#str(patients[,130:171])
#str(patients[,172:179])
#str(patients[,179:200])
#str(patients[,201:460])

patients$PATIENT_ID <-  as.character(patients$PATIENT_ID)
patients$HCV_STATUS <-  as.factor(patients$HCV_STATUS)
patients[8:122] <- sapply(patients[8:122], as.numeric)
#patients[130:160] <- sapply(patients[130:171], as.numeric)
#patients[130:171] <- sapply(patients[130:171], as.numeric)
#patients[173:177] <- sapply(patients[173:177], as.numeric)
#patients[179:460] <- sapply(patients[179:460], as.numeric)

patients$Insurance_Gap <- as.factor(patients$Insurance_Gap)
patients$Insurance_Aided <- as.factor(patients$Insurance_Aided)

#check that there are no na's in the dataset
sum(is.na(patients))

#Demographic variables = 4-7
#ICD codes grouped by HEDIS value sets = 8-63
#CPT codes by HEDIS value sets = 64-122
#Encounter variables = 123-129
#ACS variables = 130-171
#Social variables = 172-179
#ICD grouped by CCS variables = 180-460

# leave baselinemodel variables only
patients<-patients[,c(1:129,172:179)]
dim(patients)

```

#Demographic variables = 4-7
#ICD codes grouped by HEDIS value sets = 8-63
#CPT codes by HEDIS value sets = 64-122
#Encounter variables = 123-129
#ACS variables = 130-171
#Social variables = 172-179
#ICD grouped by CCS variables = 180-460


```{r}
##### BUILD SAMPLED DATASETS

set.seed(12345)

### build train data set to use with different sampling techniques
#separate positive and negative patients into separate tables
patients_negative_imb<-subset(patients,patients$HCV_STATUS==0)
patients_positive_imb<-subset(patients,patients$HCV_STATUS==1)

#randomly select 70% of the negative patients for the train set
train_negative_imb<-sample_frac(patients_negative_imb, 0.7)
nrow(train_negative_imb)

#randomly select 70% of the positive patients for the train set
train_positive_imb<-sample_frac(patients_positive_imb, 0.7)
nrow(train_positive_imb)

## build test data set
#select the remainder of the negaive patients that are not part of the training set to be part of the test set
test_negative_imb<-anti_join(patients_negative_imb,train_negative_imb)
nrow(test_negative_imb)
#select the rematiner of the positive patients that are not part of the training set to be part of the test set
test_positive_imb<-anti_join(patients_positive_imb,train_positive_imb)
nrow(test_positive_imb)

### bind the two tables (positive and negative for test and train)
train_patients_imb<-rbind(train_negative_imb,train_positive_imb)
test_patients_imb<-rbind(test_negative_imb,test_positive_imb)

train_patients_vars_imb<-train_patients_imb[,3:ncol(train_patients_imb)]
test_patients_vars_imb<-test_patients_imb[,3:ncol(test_patients_imb)]

dim(train_patients_vars_imb)

#check table
table(train_patients_vars_imb$HCV_STATUS)

#check classes distribution
prop.table(table(train_patients_vars_imb$HCV_STATUS))
#The positive patients are less than 1% of the sample


##IMBALANCED DATA SETS SAMPLING TECHNIQUES

##1. MANUAL SAMPLING
### build train data set
#separate positive and negative patients into two separate tables
patients_negative<-subset(patients,patients$HCV_STATUS==0)
patients_positive<-subset(patients,patients$HCV_STATUS==1)

#select 70% of the negative patients to be part of the training set
train_negative<-sample_frac(patients_negative, 0.7)
nrow(train_negative)

#select 70% of the positive patients to be part of the training set
train_positive<-sample_frac(patients_positive, 0.7)
nrow(train_positive)
#repeat the positive patients 50 times to balance the imbalanced positives in the sample
train_positive<-train_positive[rep(1:nrow(train_positive),each=50),] 
nrow(train_positive)

 ## build test data set
#select the negative patients who are not part of the training set to be part of the testing set
test_negative<-anti_join(patients_negative,train_negative)
nrow(test_negative)

#select the positive patients who are not part of the training set to be part of the test set
test_positive<-anti_join(patients_positive,train_positive)
nrow(test_positive)
test_positive<-test_positive[rep(1:nrow(test_positive),each=50),] 
nrow(test_positive)

### bind the two tables (positive and negative for test and train)
train_patients<-rbind(train_negative,train_positive)
table(train_patients$HCV_STATUS)
prop.table(table(train_patients$HCV_STATUS))

test_patients<-rbind(test_negative,test_positive)
table(test_patients$HCV_STATUS)
prop.table(table(test_patients$HCV_STATUS))

#remove variables that won't be used in the model
train_patients_vars<-train_patients[,3:ncol(train_patients)]
test_patients_vars<-test_patients[,3:ncol(test_patients)]


# Use the rose package for different sampling techniques

#2. OVER-SAMPLING TECHNIQUE
#oversample the positive patients until the number of entries in the train dataset is 300K
data_balanced_over <- ovun.sample(HCV_STATUS ~ ., data = train_patients_vars_imb, method = "over",N = 350000)$data
table(data_balanced_over$HCV_STATUS)

#oversample the positive patients until the number of entries in the test dataset is 150K. To maintain 70/30 ratio of train to test
test_balanced_over <- ovun.sample(HCV_STATUS ~ ., data = test_patients_vars_imb, method = "over",N = 150000)$data
table(test_balanced_over$HCV_STATUS)

#make the number of items in the samples the same so the data set is balanced

#In the code above, method over instructs the algorithm to perform over sampling. N refers to number of observations in the resulting balanced set. 

#3. UNDER-SAMPLING TECHNIQUE
#Similarly, we can perform undersampling as well. Remember, undersampling is done without replacement.
data_balanced_under <- ovun.sample(HCV_STATUS ~ ., data = train_patients_vars_imb, method = "under", N = 3500, seed = 1)$data
table(data_balanced_under$HCV_STATUS)

#To maintain 70/30 ratio of train to test
test_balanced_under <- ovun.sample(HCV_STATUS ~ ., data = test_patients_vars_imb, method = "under", N = 1500, seed = 1)$data
table(test_balanced_under$HCV_STATUS)



#4. BOTH UNDER AND OVER-SAMPLE
#Now the data set is balanced. But, you see that we've lost significant information from the sample. Let's do both undersampling and oversampling on this imbalanced data. This can be achieved using method = "both". In this case, the minority class is oversampled with replacement and majority class is undersampled without replacement.
data_balanced_both <- ovun.sample(HCV_STATUS ~ ., data = train_patients_vars_imb, method = "both", p=0.5,N=100000, seed = 1)$data
table(data_balanced_both$HCV_STATUS)

#To maintain 70/30 ratio of train to test
test_balanced_both <- ovun.sample(HCV_STATUS ~ ., data = test_patients_vars_imb, method = "both", p=0.5,N=33000, seed = 1)$data
table(test_balanced_both$HCV_STATUS)

#p refers to the probability of positive class in newly generated sample.The data generated from oversampling have expected amount of repeated observations. Data generated from undersampling is deprived of important information from the original data. This leads to inaccuracies in the resulting performance. To encounter these issues, ROSE helps us to generate data synthetically as well. The data generated using ROSE is considered to provide better estimate of original data.

#5. START ROSE SAMPLING
data.rose <- ROSE(HCV_STATUS ~ ., data = train_patients_vars_imb, seed = 1)$data
table(data.rose$HCV_STATUS)

test.rose <- ROSE(HCV_STATUS ~ ., data = test_patients_vars_imb, seed = 1)$data
table(test.rose$HCV_STATUS)


```



```{r}

## LOGISTIC MODELS FOR CUSTOM SAMPLING TECHNIQUES

##1. LOGISTIC MODEL ON MANUAL SAMPLING TECHNIQUES
logistic_model<-glm(HCV_STATUS~. ,data=train_patients_vars, family=binomial(link=logit))
summary(logistic_model)

#predict using the model and test data set
xp<-predict(logistic_model,newdata=test_patients_vars,type="response")
sampled_logloss_pred<-xp
#Use .5 as the threshold probability for whether patient is diagnosed as positive or negative
xp[xp>=0.5]=1
xp[xp<0.5]=0
table(test_patients_vars$HCV_STATUS,xp)
round(prop.table(table(test_patients_vars$HCV_STATUS,xp),1),2)


##2. LOGISTIC MODEL ON OVERSAMPLING TECHNIQUES
logistic_model_over<-glm(HCV_STATUS~. ,data=data_balanced_over, family=binomial(link=logit))
summary(logistic_model_over)

#predict using the model and test data set
xp_bal_over=logistic_model_over$fitted.values
xp_pred_over<-predict(logistic_model_over,newdata=test_balanced_over,type="response")
OVER_logloss_pred<-xp_pred_over
#Use .5 as the threshold probability for whether patient is diagnosed as positive or negative
xp_pred_over[xp_pred_over>=0.5]=1
xp_pred_over[xp_pred_over<0.5]=0
table(test_balanced_over$HCV_STATUS,xp_pred_over)
round(prop.table(table(test_balanced_over$HCV_STATUS,xp_pred_over),1),2)

##3. LOGISTIC MODEL ON UNDERSAMPLING TECHNIQUES
#HH - try this sampling technique once the Age category in the patients file has been binned by generation. Does not work now because there are too many categories/bins

#logistic_model_under<-glm(HCV_STATUS~. ,data=data_balanced_under, family=binomial(link=logit)) #getting error: fitted probabilities numerically 0 or 1 occurred.>
#summary(logistic_model_under)

#xp_bal_under=logistic_model_under$fitted.values
#xp_pred_under<-predict(logistic_model_under,newdata=test_balanced_under,type="response")
#UNDER_logloss_pred<-xp_pred_under
#xp_pred_under[xp_pred_under>=0.5]=1
#xp_pred_under[xp_pred_under<0.5]=0
#table(test_balanced_under$HCV_STATUS,xp_pred_under)
#round(prop.table(table(test_balanced_under$HCV_STATUS,xp_pred_under),1),2)

##4. LOGISTIC MODEL ON BOTH-WAY SAMPLING TECHNIQUES
logistic_model_both<-glm(HCV_STATUS~. ,data=data_balanced_both, family=binomial(link=logit))
summary(logistic_model_both)

xp_pred_both<-predict(logistic_model_both,newdata=test_balanced_both,type="response")
BOTH_logloss_pred<-xp_pred_both
xp_pred_both[xp_pred_both>=0.5]=1
xp_pred_both[xp_pred_both<0.5]=0
table(test_balanced_both$HCV_STATUS,xp_pred_both)
round(prop.table(table(test_balanced_both$HCV_STATUS,xp_pred_both),1),2)

##5. LOGISTIC MODEL ON ROSE SAMPLING TECHNIQUES
logistic_model_rose<-glm(HCV_STATUS~. ,data=data.rose, family=binomial(link=logit))
summary(logistic_model_rose)

xp_pred_rose<-predict(logistic_model_rose,newdata=test.rose,type="response")
ROSE_logloss_pred<-xp_pred_rose
xp_pred_rose[xp_pred_rose>=0.5]=1
xp_pred_rose[xp_pred_rose<0.5]=0
table(test.rose$HCV_STATUS,xp_pred_rose)
round(prop.table(table(test.rose$HCV_STATUS,xp_pred_rose),1),2)

```



```{r}

### METRICS COMPARISON FOR LOGISTIC MODEL
library(Metrics)
## HH Add ROC curvse, cohen's kappa, F metrics



#1. MANUAL SAMPLING MODEL
sampled_log<-table(test_patients_vars$HCV_STATUS,xp); sampled_log
round(prop.table(table(test_patients_vars$HCV_STATUS,xp),1),2)
sampled_log_miscat<-(sampled_log[1,2]+sampled_log[2,1])/(sampled_log[1,2]+sampled_log[1,1]+sampled_log[2,1]+sampled_log[1,2])
sampled_log_miscat
sampled_logloss<-logLoss(as.numeric(test_patients_vars$HCV_STATUS), sampled_logloss_pred)
sampled_logloss
specificity_log = sampled_log[1,1]/(sampled_log[1,1]+sampled_log[2,1]); specificity_log
##extract significant variables and list
sampled_log_sig_vars <- summary(logistic_model)$coeff[-1,4] < 0.05 
# select sig. variables
sampled_log_sig_vars_names <- names(sampled_log_sig_vars)[sampled_log_sig_vars == TRUE] 
sampled_log_sig_vars; 
#the number of significant variables is: 
length(sampled_log_sig_vars_names)
#the names of the significant variables
sampled_log_sig_vars_names


#2. OVERSAMPLING MODEL
over_samp_log<-table(test_balanced_over$HCV_STATUS,xp_pred_over);over_samp_log
round(prop.table(table(test_balanced_over$HCV_STATUS,xp_pred_over),1),2)
over_samp_miscat<-(over_samp_log[1,2]+over_samp_log[2,1])/(over_samp_log[1,2]+over_samp_log[1,1]+over_samp_log[2,1]+over_samp_log[1,2])
over_samp_miscat
OVER_logloss<-logLoss(as.numeric(test_patients_vars$HCV_STATUS), OVER_logloss_pred)
OVER_logloss
specificity_OVER = over_samp_log[1,1]/(over_samp_log[1,1]+over_samp_log[2,1]); specificity_OVER
##extract significant variables and list
Over_sampled_log_sig_vars <- summary(logistic_model_over)$coeff[-1,4] < 0.05 
# select sig. variables
Over_sampled_log_sig_vars_names <- names(Over_sampled_log_sig_vars)[Over_sampled_log_sig_vars == TRUE] 
Over_sampled_log_sig_vars; 
#the number of significant variables is: 
length(Over_sampled_log_sig_vars_names)
#the names of the significant variables
sampled_log_sig_vars_names


#3. UNDERSAMPLING MODEL
#HH - try this sampling technique once the Age category in the patients file has been binned by generation. Does not work now because there are too many categories/bins

#under_samp_log<-table(test_balanced_under$HCV_STATUS,xp_pred_under);under_samp_log
#round(prop.table(table(test_balanced_under$HCV_STATUS,xp_pred_under),1),2)
#under_samp_miscat<-(under_samp_log[1,2]+under_samp_log[2,1])/(under_samp_log[1,2]+under_samp_log[1,1]+under_samp_log[2,1]+under_samp_log[1,2])
#under_samp_miscat
#UNDER_logloss<-logLoss(as.numeric(test_patients_vars$HCV_STATUS), UNDER_logloss_pred)
#UNDER_logloss

#4. BOTH WAY SAMPLING MODEL
both_samp_log<-table(test_balanced_both$HCV_STATUS,xp_pred_both);both_samp_log
round(prop.table(table(test_balanced_both$HCV_STATUS,xp_pred_both),1),2)
both_samp_miscat<-(both_samp_log[1,2]+both_samp_log[2,1])/(both_samp_log[1,2]+both_samp_log[1,1]+both_samp_log[2,1]+both_samp_log[1,2])
both_samp_miscat
BOTH_logloss<-logLoss(as.numeric(test_patients_vars$HCV_STATUS), BOTH_logloss_pred)
BOTH_logloss
specificity_BOTH = both_samp_log[1,1]/(both_samp_log[1,1]+both_samp_log[2,1]); specificity_BOTH
# select sig. variables
Both_sampled_log_sig_vars_names <- names(Both_sampled_log_sig_vars)[Both_sampled_log_sig_vars == TRUE] 
Both_sampled_log_sig_vars; 
#the number of significant variables is: 
length(Both_sampled_log_sig_vars_names)
#the names of the significant variables
Both_sampled_log_sig_vars_names


#5. ROSE SAMPLING MODEL
rose_samp_log<-table(test.rose$HCV_STATUS,xp_pred_rose);rose_samp_log
round(prop.table(table(test.rose$HCV_STATUS,xp_pred_rose),1),2)
rose_samp_miscat<-(rose_samp_log[1,2]+rose_samp_log[2,1])/(rose_samp_log[1,2]+rose_samp_log[1,1]+rose_samp_log[2,1]+rose_samp_log[1,2])
rose_samp_miscat
ROSE_logloss<-logLoss(as.numeric(test_patients_vars$HCV_STATUS), ROSE_logloss_pred)
ROSE_logloss
specificity_ROSE = rose_samp_log[1,1]/(rose_samp_log[1,1]+rose_samp_log[2,1]); specificity_ROSE

##extract significant variables and list
Rose_sampled_log_sig_vars <- summary(logistic_model_rose)$coeff[-1,4] < 0.05 
# select sig. variables
Rose_sampled_log_sig_vars_names <- names(Rose_sampled_log_sig_vars)[Rose_sampled_log_sig_vars == TRUE] 
Rose_sampled_log_sig_vars; 
#the number of significant variables is: 
length(Rose_sampled_log_sig_vars_names)
#the names of the significant variables
Rose_sampled_log_sig_vars_names

```





```{r}
#REGRESSION TREE MODEL WITH VARIOUS SAMPLING TECHNIQUES

# 1. MANUAL SAMPLING METHOD WITH REGRESSION TREE MODEL
tree.man <- rpart(HCV_STATUS ~ ., data = train_patients_vars)
pred.tree.man <- predict(tree.man, newdata = test_patients_vars)


#2. OVER-SAMPLING METHOD WITH REGRESSION TREE MODEL
tree.over <- rpart(HCV_STATUS ~ ., data = data_balanced_over)
pred.tree.over <- predict(tree.over, newdata = test_balanced_over)

#3. UNDER-SAMPLING METHOD WITH REGRESSION TREE MODEL


#4. BOTH SAMPOLING METHOD WITH REGREASSION TREE
tree.both <- rpart(HCV_STATUS ~ ., data = data_balanced_both)
pred.tree.both <- predict(tree.both, newdata = test_balanced_both)


#5. ROSE SAMPLING METHOD WITH REGRESSION TREE
tree.rose <- rpart(HCV_STATUS ~ ., data = data.rose)
pred.tree.rose <- predict(tree.rose, newdata = test.rose, type = "prob")


```


```{r}
#REGRESSION TREE MODEL METRICS

#1. MANUAL SAMPLING METHOD WITH REGRESSION TREE MODEL METRICS
pred.tree.man<-pred.tree.man[,2]
pred.tree.man.logloss<-pred.tree.man
pred.tree.man[pred.tree.man>=0.5]=1
pred.tree.man[pred.tree.man<0.5]=0
man_samp_tree<-table(test_patients_vars$HCV_STATUS,pred.tree.man)
round(prop.table(table(test_patients_vars$HCV_STATUS,pred.tree.man),1),2)
Man_tree_samp_miscat<-(man_samp_tree[1,2]+man_samp_tree[2,1])/(man_samp_tree[1,2]+man_samp_tree[1,1]+man_samp_tree[2,1]+man_samp_tree[1,2]);Man_tree_samp_miscat
Man_logloss_tree<-logLoss(as.numeric(test_patients_vars$HCV_STATUS), pred.tree.man.logloss)
Man_logloss_tree


#2. OVERSAMPLING REGRESSIN TREE MODEL METRICS
pred.tree.over<-pred.tree.over[,2]
pred.tree.over.logloss<-pred.tree.over
pred.tree.over[pred.tree.over>=0.5]=1
pred.tree.over[pred.tree.over<0.5]=0
over_samp_tree<-table(test_balanced_over$HCV_STATUS,pred.tree.over)
round(prop.table(table(test_balanced_over$HCV_STATUS,pred.tree.over),1),2)
Over_tree_samp_miscat<-(over_samp_tree[1,2]+over_samp_tree[2,1])/(over_samp_tree[1,2]+over_samp_tree[1,1]+over_samp_tree[2,1]+over_samp_tree[1,2]);Over_tree_samp_miscat
OVER_logloss_tree<-logLoss(as.numeric(test_balanced_over$HCV_STATUS), pred.tree.over.logloss)
OVER_logloss_tree


#3. UNDER-SAMPLING METHOD WITH REGRESSION TREE MODEL METRICS


#4. BOTH SAMPOLING METHOD WITH REGREASSION TREE METRICS
pred.tree.both<-pred.tree.both[,2]
pred.tree.both.logloss<-pred.tree.both
pred.tree.both[pred.tree.both>=0.5]=1
pred.tree.both[pred.tree.both<0.5]=0
both_samp_tree<-table(test_balanced_both$HCV_STATUS,pred.tree.both)
round(prop.table(table(test_balanced_both$HCV_STATUS,pred.tree.both),1),2)
Both_tree_samp_miscat<-(both_samp_tree[1,2]+both_samp_tree[2,1])/(both_samp_tree[1,2]+both_samp_tree[1,1]+both_samp_tree[2,1]+both_samp_tree[1,2]);Both_tree_samp_miscat
BOTH_logloss_tree<-logLoss(as.numeric(test_balanced_both$HCV_STATUS), pred.tree.both.logloss)
BOTH_logloss_tree


#5. ROSE SAMPLING METHOD WITH REGRESSION TREE METRICS
#HH - the rose regression tree is producing predictions of 0/1 only, unlike the other sampling techniquest that produced probabilities. why?
pred.tree.rose<-pred.tree.rose[,2]
pred.tree.rose.logloss<-pred.tree.rose
pred.tree.rose[pred.tree.rose>=0.5]=1
pred.tree.rose[pred.tree.rose<0.5]=0
rose_samp_tree<-table(test.rose$HCV_STATUS,pred.tree.rose)
round(prop.table(table(test.rose$HCV_STATUS,pred.tree.rose),1),2)
Rose_tree_samp_miscat<-(rose_samp_tree[1,2]+rose_samp_tree[2,1])/(rose_samp_tree[1,2]+rose_samp_tree[1,1]+rose_samp_tree[2,1]+rose_samp_tree[1,2]);Rose_tree_samp_miscat
ROSE_logloss_tree<-logLoss(as.numeric(test.rose$HCV_STATUS), pred.tree.rose.logloss)
ROSE_logloss_tree


```




```{r}

#LOGISTIC WITH LASSO


#OVERSAMPLING TECHNIQUE FOR LOGISTIC WITH LASSO

train.X<- data.matrix(data_balanced_over[,-1])
class(train.X)
train.Y <- data_balanced_over[,1]
str(train.Y)

test.X<- data.matrix(test_balanced_over[,-1])
class(test.X)
test.Y <- test_balanced_over[,1]

library(glmnet)
lasso.train.over <- glmnet(x=train.X,y=train.Y,family = "binomial", alpha=1,nlambda=100,lambda.min.ratio=.0001,standardize=F)

set.seed(1)
cv.out <- cv.glmnet(x=train.X,y=train.Y,alpha=1, family="binomial")
plot(cv.out)

bestlam <- cv.out$lambda.min

lasso.train.pred <- predict(lasso.train.over,s=bestlam,newx=train.X, type = "class")
#confusion.train.diabetes <- confusionMatrix(lasso.train.pred, train.Y); confusion.train.diabetes

#Predict test Y's using best lambda from the training set model and test dataset X's
lasso.test.pred <- predict(lasso.train.over,s=bestlam,newx=test.X, type = "class")

lasso.test.prob <- predict(lasso.train.over,s=bestlam,newx=test.X, type = "response")

#Confusion Matrix
library(caret)

confusion.lasso.over <- confusionMatrix(lasso.test.pred, test.Y)
confusion.lasso.over
```










```{r}
#######STOP HERE - BELOW CODE NOT CLEAN############

#tree.rose <- rpart(cls ~ ., data = data.rose)
tree.under <- rpart(HCV_STATUS ~ ., data = data_balanced_under)
tree.both <- rpart(HCV_STATUS ~ ., data = data_balanced_both)

#make predictions on unseen data
#pred.tree.rose <- predict(tree.rose, newdata = hacide.test)
pred.tree.under <- predict(tree.under, newdata = test_patients_vars_imb)
pred.tree.both <- predict(tree.both, newdata = test_patients_vars_imb)

#It's time to evaluate the accuracy of respective predictions. Using inbuilt function roc.curve allows us to capture roc metric.

#AUC ROSE
#roc.curve(test_patients_vars_imb$HCV_STATUS, pred.tree.rose[,2])

#AUC Oversampling
#roc.curve(test_patients_vars_imb$HCV_STATUS, pred.tree.over[,2])

#AUC Undersampling
#roc.curve(test_patients_vars_imb$HCV_STATUS, pred.tree.under[,2])

#AUC Both
#roc.curve(test_patients_vars_imb$HCV_STATUS, pred.tree.both[,2])



##### START - ROSE holdout calculation##################
#This package also provide us methods to check the model accuracy using holdout and bagging method. This helps us to ensure that our resultant predictions doesn't suffer from high variance.

#ROSE.holdout <- ROSE.eval(cls ~ ., data = hacide.train, learner = rpart, method.assess = "holdout", extr.pred = function(obj)obj[,2], seed = 1)
#ROSE.holdout
#We see that our accuracy retains at ~ 0.98 and shows that our predictions aren't suffering from high variance. Similarly, you can use bootstrapping by setting method.assess to "BOOT". The parameter extr.pred is a function which extracts the column of probabilities belonging to positive class.

#ROSE.holdout <- ROSE.eval(cls ~ ., data = hacide.train, learner = rpart, method.assess = "BOOT", extr.pred = function(obj)obj[,2], seed = 1)
#ROSE.holdout

##### END - ROSE holdout calculation##################



```


```{r}
##CINDY'S CODE FOR LOGISTIC WITH LASSO

flat.file.diabetes<-read.csv(file=paste(datapath,"flat.file.diabetes.csv",sep="/"))
str(flat.file.diabetes)
dim(flat.file.diabetes)
flat.file.diabetes<- lapply(flat.file.diabetes, as.numeric)
#flat.file.diabetes <- as.matrix(sapply(flat.file.diabetes, as.numeric))  
flat.file.diabetes <- as.data.frame(flat.file.diabetes)

train.diabetes <- flat.file.diabetes[1:6648,]
dim(train.diabetes)
str(train.diabetes)

test.diabetes <- flat.file.diabetes[6649:9948,]
dim(test.diabetes)
str(test.diabetes)

train.X<- data.matrix(train.diabetes[,-1])
class(train.X)
train.Y <- train.diabetes[,1]
str(train.Y)

test.X<- data.matrix(test.diabetes[,-1])
class(test.X)
test.Y <- test.diabetes[,1]

library(glmnet)
lasso.train.diabetes <- glmnet(x=train.X,y=train.Y,family = "binomial", alpha=1,nlambda=100,lambda.min.ratio=.0001,standardize=F)

set.seed(1)
cv.out <- cv.glmnet(x=train.X,y=train.Y,alpha=1)
plot(cv.out)

bestlam <- cv.out$lambda.min

lasso.train.pred <- predict(lasso.train.diabetes,s=bestlam,newx=train.X, type = "class")
confusion.train.diabetes <- confusionMatrix(lasso.train.pred, train.Y); confusion.train.diabetes

#Predict test Y's using best lambda from the training set model and test dataset X's
lasso.test.pred <- predict(lasso.train.diabetes,s=bestlam,newx=test.X, type = "class")

lasso.test.prob <- predict(lasso.train.diabetes,s=bestlam,newx=test.X, type = "response")
#To test the accuracy of your algorithm, calculate sensitivity, specificity and the AUC of your forecasting.

#Accuracy: Overall, how often is the classifier correct?

#True Positive Rate: When the person has disease, how often test result is positive?  Sensitivity or Recall
#(truePositiveRate=TP/Disease)

#Specificity:Given that the person has no disease, how often the test is negative? Same as 1- Fasle Postivie Rate
#(specificity = TN/Nodisease)

#AUC(Area Under Curve)

#Confusion Matrix
library(caret)

confusion.lasso.diabetes <- confusionMatrix(lasso.test.pred, test.Y)
?confusionMatrix
confusion.lasso.diabetes

#It is a plot of the true positive rate against the false positive rate for the different possible cutpoints of a diagnostic test.
#library(Deducer)????? cant run this package because of rJava

#roc.lasso <- rocplot(lasso.test.pred, diag=TRUE, AUC=TRUE)
#rocplot(logistic.model,diag=TRUE,pred.prob.labels=FALSE,prob.label.digits=3,AUC=TRUE)

library(pROC)
#auc(predictions$survived, predictions$pred) lasso.test.pred, test.Y
auc(test.Y, lasso.test.prob)

lasso.test.prob <- as.vector(lasso.test.prob)
    
roc.lasso <- roc(lasso.test.pred, test.Y)
plot(roc.lasso, print.auc=TRUE, smooth = TRUE,col = "blue")
   
roc.object <- roc(response = test.Y, predictor = lasso.test.prob) 
lasso.auc<- auc(test.Y, lasso.test.prob); lasso.auc ## Area under the curve: 0.9978 plot(roc.object) 
lasso.roc <- plot(roc.object, col="red", main = "ROC Curve for Logistic Regression with Lasso")

?auc

library(ROCR)

pred <- prediction(lasso.test.prob, test.Y)

pred2 <- prediction(abs(lasso.test.prob + 
                            rnorm(length(lasso.test.prob), 0, 0.1)), 
                    test.Y)
perf <- performance( pred, "tpr", "fpr" )
perf2 <- performance(pred2, "tpr", "fpr")
plot( perf, colorize = TRUE)
plot(perf2, add = TRUE, colorize = TRUE)


x   <- prediction(lasso.test.prob, test.Y)
ROC <- performance(x, "tpr", "fpr")
plot(ROC, main = "ROC Curve for Logistic Regression with Lasso", col = "red")

matplot(1:length(lasso.test.prob),lasso.test.prob,pch=1,ylab="Probability",xlab="Index")


beta  <- as.vector( t(coef(lasso.train.diabetes,s=bestlam))) 
beta
lasso.coef<-predict(lasso.train.diabetes,type="coefficients",s=bestlam)
lasso.coef

counts.train <- train.diabetes$DMIndicator
counts.train <- table(train.diabetes$DMIndicator)
counts.test <- table(test.diabetes$DMIndicator)
counts.all <- table(counts.train, counts.test)
counts.train
counts.test
counts.all
sum(flat.file.diabetes$DMIndicator)/nrow(flat.file.diabetes)
sum(train.diabetes$DMIndicator)
sum(test.diabetes$DMIndicator)/nrow(test.diabetes)
sum(train.diabetes$DMIndicator)/nrow(train.diabetes)
barplot(c(counts.train, counts.test), main = "Number of Patients with and without a Type II Diabetes Diagnosis", 
            ylab = "Number of Patients", 
            col = c("green", "red"), 
            horiz=FALSE, names.arg=c("No", "Yes", "No", "Yes"))
            

library(plotly)
p <- plot_ly(
    x = c("No", "Yes"),
    y = c(5405, 1243),
    name = "Train Dataset",
    colors = c("green", "red"),
    showlegend = TRUE,
    type = "bar")
p

p2 <- add_trace(
    p,
    x = c("No", "Yes"),
    y = c(2639, 661),
    name = "Test Dataset",
    colors = c("green", "red"),
    type = "bar")
p2

x <- list (title = "Diagnosis")
y <- list (title = "Number of Patients")
p3 <- layout(p2, barmode = "stack") %>%
            layout(xaxis = x, yaxis = y)
p3

p4 <- layout(p3, title = "Number of Patients in Dataset with and without Type II Diabetes Diagnosis")
p4


```

